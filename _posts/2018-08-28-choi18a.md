---
title: On the Relative Expressiveness of Bayesian and Neural Networks
abstract: A neural network computes a function.  A central property of neural networks
  is that they are “universal approximators:” for a given continuous function, there
  exists a neural network that can approximate it arbitrarily well, given enough neurons
  (and some additional assumptions).  In contrast, a Bayesian network is a model,
  but each of its queries can be viewed as computing a function.  In this paper, we
  identify some key distinctions between the functions computed by neural networks
  and those by Bayesian network queries, showing that the former are more expressive
  than the latter.  Moreover, we propose a simple augmentation to Bayesian networks
  (a testing operator), which enables their queries to become “universal approximators”
  as well.
section: Accepted Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: choi18a
month: 0
tex_title: On the Relative Expressiveness of Bayesian and Neural Networks
firstpage: 157
lastpage: 168
page: 157-168
order: 157
cycles: false
bibtex_author: Choi, Arthur and Darwiche, Adnan
author:
- given: Arthur
  family: Choi
- given: Adnan
  family: Darwiche
date: 2018-08-28
address: 
publisher: PMLR
container-title: Proceedings of the Ninth International Conference on Probabilistic
  Graphical Models
volume: '72'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 8
  - 28
pdf: http://proceedings.mlr.press/v72/choi18a/choi18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
